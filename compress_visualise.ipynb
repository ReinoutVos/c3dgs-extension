{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression Pipeline:\n",
    "\n",
    "\n",
    "<div style=\"background-color: white; padding: 10px;\">\n",
    "    <img src=\"./docs/static/img/pipeline.svg\" alt=\"SVG Image\" width=\"1500px\" />\n",
    "</div>\n",
    "\n",
    "Instead of running the compression pipeline all at once, here you can run it step-by-step and explore the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First simulate the command-line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_args = [\n",
    "        \"--model_path\", \"./input_models/flower_hq\",\n",
    "        \"--data_device\", \"cuda\",\n",
    "        \"--output_vq\", \"./output\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from arguments import (\n",
    "    CompressionParams,\n",
    "    ModelParams,\n",
    "    OptimizationParams,\n",
    "    PipelineParams,\n",
    "    get_combined_args,\n",
    ")\n",
    "\n",
    "from compress import unique_output_folder, calc_importance\n",
    "from gaussian_renderer import GaussianModel\n",
    "from scene import Scene\n",
    "from compression.vq import CompressionSettings, compress_color, compress_covariance\n",
    "from typing import Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments(simulated_args=[]):\n",
    "    # Initialize the argument parser\n",
    "    parser = ArgumentParser(description=\"Compression script parameters\")\n",
    "    \n",
    "    # Add the same argument groups as in the script\n",
    "    model = ModelParams(parser, sentinel=True)\n",
    "    model.data_device = \"cuda\"\n",
    "    pipeline = PipelineParams(parser)\n",
    "    op = OptimizationParams(parser)\n",
    "    comp = CompressionParams(parser)\n",
    "    \n",
    "    # Combine simulated args with parser arguments\n",
    "    args = get_combined_args(parser, simulated_args)\n",
    "    return args, model, pipeline, op, comp\n",
    "\n",
    "\n",
    "args, model, pipeline, op, comp = parse_arguments(simulated_args)\n",
    "\n",
    "# Set output folder if not specified\n",
    "if args.output_vq is None:\n",
    "    args.output_vq = unique_output_folder()\n",
    "\n",
    "# Extract parameters\n",
    "model_params = model.extract(args)\n",
    "optim_params = op.extract(args)\n",
    "pipeline_params = pipeline.extract(args)\n",
    "comp_params = comp.extract(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Gaussians\n",
    "gaussians = GaussianModel(\n",
    "    model_params.sh_degree, quantization=not optim_params.not_quantization_aware\n",
    ")\n",
    "\n",
    "# Initialize the scene (test cameras + train cameras)\n",
    "scene = Scene(\n",
    "    model_params, gaussians, load_iteration=comp_params.load_iteration, shuffle=True\n",
    ")\n",
    "\n",
    "# Extract the Gaussians from the pre-trained model (checkpoint)\n",
    "if comp_params.start_checkpoint:\n",
    "    (checkpoint_params, first_iter) = torch.load(comp_params.start_checkpoint)\n",
    "    gaussians.restore(checkpoint_params, optim_params)\n",
    "\n",
    "\n",
    "timings ={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Parameter Sensitivity\n",
    "Note: The authors use 'sensitivity' and 'importance' interchangeably, this is very confusing I know "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "color_importance, gaussian_sensitivity = calc_importance(\n",
    "    gaussians, scene, pipeline_params\n",
    ")\n",
    "end_time = time.time()\n",
    "timings[\"sensitivity_calculation\"] = end_time-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_importance_include = torch.tensor(0.6 * 1e-6)\n",
    "gaussian_importance_include = torch.tensor(0.3 * 1e-5)\n",
    "\n",
    "color_above_threshold = (color_importance > color_importance_include).sum().item()\n",
    "total_elements_color = color_importance.numel()\n",
    "\n",
    "gaussian_above_threshold = (gaussian_sensitivity > gaussian_importance_include).sum().item()\n",
    "total_elements_gaussian = gaussian_sensitivity.numel()\n",
    "\n",
    "color_threshold = 1.0 - (color_above_threshold / total_elements_color)\n",
    "gaussian_threshold = 1.0 - (gaussian_above_threshold / total_elements_gaussian)\n",
    "\n",
    "print(f\"Percentage of color_importance values below the threshold: {color_threshold:.2f}%\")\n",
    "print(f\"Percentage of gaussian_importance values below the threshold: {gaussian_threshold:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the tensors\n",
    "color_importance_norm = torch.nn.functional.normalize(color_importance.clone(), p=2)\n",
    "gaussian_sensitivity_norm = torch.nn.functional.normalize(gaussian_sensitivity.clone(), p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_importance_norm_np = color_importance_norm.cpu().numpy().flatten()  # Convert to numpy array if needed\n",
    "gaussian_sensitivity_norm_np = gaussian_sensitivity_norm.cpu().numpy().flatten()\n",
    "# color_threshold = color_importance_include.cpu().numpy()\n",
    "# gaussian_threshold = gaussian_importance_include.cpu().numpy()\n",
    "\n",
    "# color_importance = color_importance.flatten()  # Convert to numpy array if needed\n",
    "# gaussian_sensitivity = gaussian_sensitivity.flatten()\n",
    "\n",
    "\n",
    "# Define the number of bins\n",
    "num_bins = 20\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "\n",
    "# Color sensitivity histogram\n",
    "axes[0].hist(\n",
    "    color_importance_norm_np,\n",
    "    bins=num_bins,\n",
    "    color=\"#1f77b4\",\n",
    "    density=True\n",
    ")\n",
    "axes[0].axvline(color_threshold, color='red', linestyle='--', label=f'Threshold ({color_threshold})')\n",
    "axes[0].set_title(\"Color Sensitivity Distribution\")\n",
    "axes[0].set_xlabel(\"Sensitivity\")\n",
    "axes[0].set_ylabel(\"Density\")\n",
    "# axes[0].set_yscale(\"log\")\n",
    "\n",
    "# Shape sensitivity histogram\n",
    "axes[1].hist(\n",
    "    gaussian_sensitivity_norm_np,\n",
    "    bins=num_bins,\n",
    "    color=\"#ff7f0e\",\n",
    "    density=True\n",
    ")\n",
    "axes[1].axvline(gaussian_threshold, color='red', linestyle='--', label=f'Threshold ({gaussian_threshold})')\n",
    "axes[1].set_title(\"Shape Sensitivity Distribution\")\n",
    "axes[1].set_xlabel(\"Sensitivity\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Sensitivity-aware vector clustering (K-Means) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def prune_gaussians(\n",
    "    gaussians: GaussianModel,\n",
    "    color_importance: torch.Tensor,\n",
    "    color_importance_n_norm: torch.Tensor,\n",
    "    gaussian_importance: torch.Tensor,\n",
    "    prune_threshold:float=0.,\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        if prune_threshold >= 0:\n",
    "            non_prune_mask = color_importance > prune_threshold\n",
    "            print(f\"prune: {(1-non_prune_mask.float().mean())*100:.2f}%\")\n",
    "            # gaussians.mask_splats(non_prune_mask)\n",
    "            # gaussian_importance = gaussian_importance[non_prune_mask]\n",
    "            # color_importance = color_importance[non_prune_mask]\n",
    "\n",
    "            # Example positions for each Gaussian (assuming each Gaussian has a 3D position)\n",
    "            positions = gaussians.get_xyz\n",
    "            positions_np = positions.cpu().numpy()\n",
    "\n",
    "            # Before pruning (all Gaussians)\n",
    "            color_importance_n_np = color_importance_n_norm.cpu().numpy()\n",
    "\n",
    "            # # Apply pruning to get the mask\n",
    "            # non_prune_mask = color_importance_n > prune_threshold\n",
    "            # non_prune_mask_np = non_prune_mask.cpu().numpy()\n",
    "\n",
    "            # # Scatter plot\n",
    "            # fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "            # # Before Pruning\n",
    "            # ax1 = fig.add_subplot(121, projection='3d')\n",
    "            # ax1.scatter(positions[:, 0], positions[:, 1], positions[:, 2], \n",
    "            #             c=color_importance_n_np, cmap='viridis', s=1)\n",
    "            # ax1.set_title(\"Before Pruning\")\n",
    "            # ax1.set_xlabel(\"X\")\n",
    "            # ax1.set_ylabel(\"Y\")\n",
    "            # ax1.set_zlabel(\"Z\")\n",
    "\n",
    "            # # # After Pruning (Only non-pruned Gaussians)\n",
    "            # # ax2 = fig.add_subplot(122, projection='3d')\n",
    "            # # ax2.scatter(positions[non_prune_mask_np, 0], positions[non_prune_mask_np, 1], positions[non_prune_mask_np, 2], \n",
    "            # #             c=color_importance_n_np[non_prune_mask_np], cmap='viridis', s=1)\n",
    "            # # ax2.set_title(\"After Pruning\")\n",
    "            # # ax2.set_xlabel(\"X\")\n",
    "            # # ax2.set_ylabel(\"Y\")\n",
    "            # # ax2.set_zlabel(\"Z\")\n",
    "\n",
    "            # plt.show()\n",
    "\n",
    "            # Create the 3D scatter plot\n",
    "            fig = go.Figure(data=[go.Scatter3d(\n",
    "                x=positions_np[:, 0],\n",
    "                y=positions_np[:, 1],\n",
    "                z=positions_np[:, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=3,\n",
    "                    color=color_importance_n_np,    # Color by sensitivity\n",
    "                    colorscale='Viridis',        # Color scale\n",
    "                    opacity=0.7,\n",
    "                    colorbar=dict(title=\"Sensitivity\")\n",
    "                )\n",
    "            )])\n",
    "\n",
    "            fig.update_layout(\n",
    "                title=\"Gaussian Positions Before Pruning\",\n",
    "                scene=dict(\n",
    "                    xaxis_title=\"X\",\n",
    "                    yaxis_title=\"Y\",\n",
    "                    zaxis_title=\"Z\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Given a vector x ∈ R^D, we define its sensitivity as the maximum over its component’s sensitivity\n",
    "    color_importance_n = color_importance.amax(-1)\n",
    "    gaussian_importance_n = gaussian_sensitivity.amax(-1)\n",
    "\n",
    "    color_importance_n_norm = color_importance_norm.amax(-1)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Initialize the color codebook\n",
    "    color_compression_settings = CompressionSettings(\n",
    "        codebook_size=comp_params.color_codebook_size,              # K = number of centroids = codebook size\n",
    "        importance_prune=comp_params.color_importance_prune,\n",
    "        importance_include=comp_params.color_importance_include,\n",
    "        steps=int(comp_params.color_cluster_iterations),\n",
    "        decay=comp_params.color_decay,\n",
    "        batch_size=comp_params.color_batch_size,\n",
    "    )\n",
    "\n",
    "    # Initialize the Gaussian shape codebook\n",
    "    gaussian_compression_settings = CompressionSettings(\n",
    "        codebook_size=comp_params.gaussian_codebook_size,\n",
    "        importance_prune=None,\n",
    "        importance_include=comp_params.gaussian_importance_include,\n",
    "        steps=int(comp_params.gaussian_cluster_iterations),\n",
    "        decay=comp_params.gaussian_decay,\n",
    "        batch_size=comp_params.gaussian_batch_size,\n",
    "    )\n",
    "\n",
    "    prune_gaussians(\n",
    "        gaussians,\n",
    "        color_importance_n,\n",
    "        color_importance_n_norm,\n",
    "        gaussian_importance_n,\n",
    "        prune_threshold=comp_params.prune_threshold,\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    timings[\"clustering\"]=end_time-start_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c3dgs_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
