{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression Pipeline:\n",
    "\n",
    "\n",
    "<div style=\"background-color: white; padding: 10px;\">\n",
    "    <img src=\"./docs/static/img/pipeline.svg\" alt=\"SVG Image\" width=\"1500px\" />\n",
    "</div>\n",
    "\n",
    "Instead of running the compression pipeline all at once, here you can run it step-by-step and explore the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First simulate the command-line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_args = [\n",
    "        \"--model_path\", \"./input_models/flower_hq\",\n",
    "        \"--data_device\", \"cuda\",\n",
    "        \"--output_vq\", \"./output\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import time\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from arguments import (\n",
    "    CompressionParams,\n",
    "    ModelParams,\n",
    "    OptimizationParams,\n",
    "    PipelineParams,\n",
    "    get_combined_args,\n",
    ")\n",
    "\n",
    "from compress import unique_output_folder, calc_importance\n",
    "from gaussian_renderer import GaussianModel\n",
    "from scene import Scene\n",
    "from compression.vq import CompressionSettings\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments(simulated_args=[]):\n",
    "    # Initialize the argument parser\n",
    "    parser = ArgumentParser(description=\"Compression script parameters\")\n",
    "    \n",
    "    # Add the same argument groups as in the script\n",
    "    model = ModelParams(parser, sentinel=True)\n",
    "    model.data_device = \"cuda\"\n",
    "    pipeline = PipelineParams(parser)\n",
    "    op = OptimizationParams(parser)\n",
    "    comp = CompressionParams(parser)\n",
    "    \n",
    "    # Combine simulated args with parser arguments\n",
    "    args = get_combined_args(parser, simulated_args)\n",
    "    return args, model, pipeline, op, comp\n",
    "\n",
    "\n",
    "args, model, pipeline, op, comp = parse_arguments(simulated_args)\n",
    "\n",
    "# Set output folder if not specified\n",
    "if args.output_vq is None:\n",
    "    args.output_vq = unique_output_folder()\n",
    "\n",
    "# Extract parameters\n",
    "model_params = model.extract(args)\n",
    "optim_params = op.extract(args)\n",
    "pipeline_params = pipeline.extract(args)\n",
    "comp_params = comp.extract(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Gaussians\n",
    "gaussians = GaussianModel(\n",
    "    model_params.sh_degree, quantization=not optim_params.not_quantization_aware\n",
    ")\n",
    "\n",
    "# Initialize the scene (test cameras + train cameras)\n",
    "scene = Scene(\n",
    "    model_params, gaussians, load_iteration=comp_params.load_iteration, shuffle=True\n",
    ")\n",
    "\n",
    "# Load the Gaussians from the pre-trained model (checkpoint) into memory\n",
    "if comp_params.start_checkpoint:\n",
    "    (checkpoint_params, first_iter) = torch.load(comp_params.start_checkpoint)\n",
    "    gaussians.restore(checkpoint_params, optim_params)\n",
    "\n",
    "\n",
    "timings = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Parameter Sensitivity\n",
    "Note: The authors use 'sensitivity' and 'importance' interchangeably, this is very confusing I know "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "color_importance, gaussian_sensitivity = calc_importance(\n",
    "    gaussians, scene, pipeline_params\n",
    ")\n",
    "end_time = time.time()\n",
    "timings[\"sensitivity_calculation\"] = end_time-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_importance_include = torch.tensor(0.6 * 1e-6)\n",
    "gaussian_importance_include = torch.tensor(0.3 * 1e-5)\n",
    "\n",
    "color_above_threshold = (color_importance > color_importance_include).sum().item()\n",
    "total_elements_color = color_importance.numel()\n",
    "\n",
    "gaussian_above_threshold = (gaussian_sensitivity > gaussian_importance_include).sum().item()\n",
    "total_elements_gaussian = gaussian_sensitivity.numel()\n",
    "\n",
    "color_threshold = 1.0 - (color_above_threshold / total_elements_color)\n",
    "gaussian_threshold = 1.0 - (gaussian_above_threshold / total_elements_gaussian)\n",
    "\n",
    "print(f\"Percentage of color_importance values below the threshold: {color_threshold:.2f}%\")\n",
    "print(f\"Percentage of gaussian_importance values below the threshold: {gaussian_threshold:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the tensors\n",
    "color_importance_norm = torch.nn.functional.normalize(color_importance.clone(), p=2)\n",
    "gaussian_sensitivity_norm = torch.nn.functional.normalize(gaussian_sensitivity.clone(), p=2)\n",
    "\n",
    "# # Normalize the tensors\n",
    "# color_importance_norm = color_importance / color_importance.max()\n",
    "# gaussian_sensitivity_norm = gaussian_sensitivity / gaussian_sensitivity.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_importance_norm_np = color_importance_norm.cpu().numpy().flatten()  # Convert to numpy array if needed\n",
    "gaussian_sensitivity_norm_np = gaussian_sensitivity_norm.cpu().numpy().flatten()\n",
    "# color_threshold = color_importance_include.cpu().numpy()\n",
    "# gaussian_threshold = gaussian_importance_include.cpu().numpy()\n",
    "\n",
    "# color_importance = color_importance.flatten()  # Convert to numpy array if needed\n",
    "# gaussian_sensitivity = gaussian_sensitivity.flatten()\n",
    "\n",
    "\n",
    "# Define the number of bins\n",
    "num_bins = 20\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "\n",
    "# Color sensitivity histogram\n",
    "axes[0].hist(\n",
    "    color_importance_norm_np,\n",
    "    bins=num_bins,\n",
    "    color=\"#1f77b4\",\n",
    "    density=True\n",
    ")\n",
    "axes[0].axvline(color_threshold, color='red', linestyle='--', label=f'Threshold ({color_threshold})')\n",
    "axes[0].set_title(\"Color Sensitivity Distribution\")\n",
    "axes[0].set_xlabel(\"Sensitivity\")\n",
    "axes[0].set_ylabel(\"Density\")\n",
    "# axes[0].set_yscale(\"log\")\n",
    "\n",
    "# Shape sensitivity histogram\n",
    "axes[1].hist(\n",
    "    gaussian_sensitivity_norm_np,\n",
    "    bins=num_bins,\n",
    "    color=\"#ff7f0e\",\n",
    "    density=True\n",
    ")\n",
    "axes[1].axvline(gaussian_threshold, color='red', linestyle='--', label=f'Threshold ({gaussian_threshold})')\n",
    "axes[1].set_title(\"Shape Sensitivity Distribution\")\n",
    "axes[1].set_xlabel(\"Sensitivity\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Sensitivity-aware vector clustering\n",
    "Note: vector clustering = vector quantization = K-Means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_gaussians(\n",
    "    gaussians: GaussianModel,\n",
    "    color_importance_n: torch.Tensor,\n",
    "    gaussian_importance_n: torch.Tensor,\n",
    "    prune_threshold:float=0.,\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        if prune_threshold >= 0:\n",
    "            non_prune_mask = color_importance_n > prune_threshold\n",
    "            print(f\"prune: {(1-non_prune_mask.float().mean())*100:.2f}%\")\n",
    "            gaussians.mask_splats(non_prune_mask)\n",
    "            gaussian_importance_n = gaussian_importance_n[non_prune_mask]\n",
    "            color_importance_n = color_importance_n[non_prune_mask]\n",
    "        \n",
    "        # if prune_threshold >= 0:\n",
    "        #     non_prune_mask = color_importance_n > prune_threshold\n",
    "        #     prune_percentage = (1 - non_prune_mask.float().mean()) * 100\n",
    "\n",
    "        #     gaussians.mask_splats(non_prune_mask)\n",
    "        #     gaussian_importance_n = gaussian_importance_n[non_prune_mask]\n",
    "        #     color_importance_n = color_importance_n[non_prune_mask]\n",
    "\n",
    "            # # Get positions for each Gaussian\n",
    "            # positions = gaussians.get_xyz\n",
    "            \n",
    "            # # Separate the positions and sensitivities based on pruning mask\n",
    "            # pos_keep = positions[non_prune_mask].cpu().numpy()\n",
    "            # pos_prune = positions[~non_prune_mask].cpu().numpy()\n",
    "\n",
    "            # fig = go.Figure()\n",
    "\n",
    "            # # Scatter plot for Gaussians that will be kept\n",
    "            # fig.add_trace(go.Scatter3d(\n",
    "            #     x=pos_prune[:, 0],\n",
    "            #     y=pos_prune[:, 1],\n",
    "            #     z=pos_prune[:, 2],\n",
    "            #     mode='markers',\n",
    "            #     marker=dict(\n",
    "            #         size=3,\n",
    "            #         color='red',    \n",
    "            #         opacity=0.5,\n",
    "            #     ),\n",
    "            #     name=\"Pruned Gaussians\"\n",
    "            # ))\n",
    "\n",
    "            # # Scatter plot for Gaussians that will be pruned\n",
    "            # fig.add_trace(go.Scatter3d(\n",
    "            #     x=pos_keep[:, 0],\n",
    "            #     y=pos_keep[:, 1],\n",
    "            #     z=pos_keep[:, 2],\n",
    "            #     mode='markers',\n",
    "            #     marker=dict(\n",
    "            #         size=3,\n",
    "            #         color='blue',\n",
    "            #         opacity=0.7,\n",
    "            #     ),\n",
    "            #     name=\"Kept Gaussians\"\n",
    "            # ))\n",
    "\n",
    "            # title = f\"Pruning {prune_percentage:.2f}% of Gaussians\"\n",
    "            # fig.update_layout(\n",
    "            #     title=title,\n",
    "            #     scene=dict(\n",
    "            #         xaxis_title=\"X\",\n",
    "            #         yaxis_title=\"Y\",\n",
    "            #         zaxis_title=\"Z\",\n",
    "            #     ),\n",
    "            #     legend=dict(x=1, y=0.9)\n",
    "            # )\n",
    "\n",
    "            # fig.show()\n",
    "\n",
    "\n",
    "# TODO: Use point cloud RGB color instead of 'blue'\n",
    "\n",
    "# from plyfile import PlyData\n",
    "# import numpy as np\n",
    "# import plotly.graph_objects as go\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# # Load points3d.ply\n",
    "# ply_path = \"./datasets/flowers/sparse/0/points3D.ply\"\n",
    "# plydata = PlyData.read(ply_path)\n",
    "\n",
    "# # Extract positions and colors\n",
    "# # positions_ply = np.vstack([plydata['vertex']['x'], plydata['vertex']['y'], plydata['vertex']['z']]).T\n",
    "# colors_ply = np.vstack([plydata['vertex']['red'], plydata['vertex']['green'], plydata['vertex']['blue']]).T\n",
    "\n",
    "# def prune_gaussians(\n",
    "#     gaussians: GaussianModel,\n",
    "#     color_importance: torch.Tensor,\n",
    "#     gaussian_importance: torch.Tensor,\n",
    "#     prune_threshold: float = 0.,\n",
    "# ):\n",
    "#     with torch.no_grad():\n",
    "#         if prune_threshold >= 0:\n",
    "#             non_prune_mask = color_importance > prune_threshold\n",
    "#             prune_percentage = (1 - non_prune_mask.float().mean()) * 100\n",
    "\n",
    "#             # Get positions and colors for each Gaussian\n",
    "#             positions = gaussians.get_xyz\n",
    "#             # colors = gaussians._features_dc  # Assuming _features_dc holds the RGB color\n",
    "\n",
    "#             # Separate the positions and colors based on pruning mask\n",
    "#             pos_keep = positions[non_prune_mask].cpu().numpy()\n",
    "#             pos_prune = positions[~non_prune_mask].cpu().numpy()\n",
    "#             color_keep = colors_ply[non_prune_mask.cpu().numpy()]  # Colors for kept Gaussians\n",
    "\n",
    "#             # Normalize colors to range [0, 1] if necessary\n",
    "#             if color_keep.max() > 1:\n",
    "#                 color_keep = color_keep / 255.0\n",
    "\n",
    "#             color_keep = np.clip(color_keep, 0, 1)\n",
    "\n",
    "#             # Convert RGB colors to hex format for plotly\n",
    "#             color_keep_hex = [mcolors.to_hex(c) for c in color_keep]\n",
    "\n",
    "#             fig = go.Figure()\n",
    "\n",
    "#             # Scatter plot for Gaussians that will be pruned\n",
    "#             fig.add_trace(go.Scatter3d(\n",
    "#                 x=pos_prune[:, 0],\n",
    "#                 y=pos_prune[:, 1],\n",
    "#                 z=pos_prune[:, 2],\n",
    "#                 mode='markers',\n",
    "#                 marker=dict(\n",
    "#                     size=3,\n",
    "#                     color='red',    \n",
    "#                     opacity=0.5,\n",
    "#                 ),\n",
    "#                 name=\"Pruned Gaussians\"\n",
    "#             ))\n",
    "\n",
    "#             # Scatter plot for Gaussians that will be kept, using actual colors\n",
    "#             fig.add_trace(go.Scatter3d(\n",
    "#                 x=pos_keep[:, 0],\n",
    "#                 y=pos_keep[:, 1],\n",
    "#                 z=pos_keep[:, 2],\n",
    "#                 mode='markers',\n",
    "#                 marker=dict(\n",
    "#                     size=3,\n",
    "#                     color=color_keep_hex,  # Use hex colors for kept Gaussians\n",
    "#                     opacity=0.7,\n",
    "#                 ),\n",
    "#                 name=\"Kept Gaussians\"\n",
    "#             ))\n",
    "\n",
    "#             title = f\"Pruning {prune_percentage:.2f}% of Gaussians\"\n",
    "#             fig.update_layout(\n",
    "#                 title=title,\n",
    "#                 scene=dict(\n",
    "#                     xaxis_title=\"X\",\n",
    "#                     yaxis_title=\"Y\",\n",
    "#                     zaxis_title=\"Z\",\n",
    "#                 ),\n",
    "#                 legend=dict(x=1, y=0.9)\n",
    "#             )\n",
    "\n",
    "#             fig.show()\n",
    "\n",
    "# import plotly.graph_objects as go\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# def prune_gaussians(\n",
    "#     gaussians: GaussianModel,\n",
    "#     color_importance: torch.Tensor,\n",
    "#     gaussian_importance: torch.Tensor,\n",
    "#     prune_threshold: float = 0.,\n",
    "# ):\n",
    "#     with torch.no_grad():\n",
    "#         if prune_threshold >= 0:\n",
    "#             non_prune_mask = color_importance > prune_threshold\n",
    "#             prune_percentage = (1 - non_prune_mask.float().mean()) * 100\n",
    "\n",
    "#             # Get positions and colors for each Gaussian\n",
    "#             positions = gaussians.get_xyz\n",
    "#             colors = gaussians._features_dc  # Assuming _features_dc holds the RGB color\n",
    "\n",
    "#             # Separate the positions and colors based on pruning mask\n",
    "#             pos_keep = positions[non_prune_mask].cpu().numpy()\n",
    "#             pos_prune = positions[~non_prune_mask].cpu().numpy()\n",
    "#             color_keep = colors[non_prune_mask].cpu().numpy()  # Colors for kept Gaussians\n",
    "\n",
    "#             # Ensure color_keep values are within the [0, 1] range\n",
    "#             color_keep = np.clip(color_keep, 0, 1)  # Clip any values outside [0, 1]\n",
    "\n",
    "#             # Convert RGB colors to hex format for plotly\n",
    "#             color_keep_hex = [mcolors.to_hex(c) for c in color_keep]\n",
    "\n",
    "#             fig = go.Figure()\n",
    "\n",
    "#             # Scatter plot for Gaussians that will be pruned\n",
    "#             fig.add_trace(go.Scatter3d(\n",
    "#                 x=pos_prune[:, 0],\n",
    "#                 y=pos_prune[:, 1],\n",
    "#                 z=pos_prune[:, 2],\n",
    "#                 mode='markers',\n",
    "#                 marker=dict(\n",
    "#                     size=3,\n",
    "#                     color='red',    \n",
    "#                     opacity=0.5,\n",
    "#                 ),\n",
    "#                 name=\"Pruned Gaussians\"\n",
    "#             ))\n",
    "\n",
    "#             # Scatter plot for Gaussians that will be kept, using actual colors\n",
    "#             fig.add_trace(go.Scatter3d(\n",
    "#                 x=pos_keep[:, 0],\n",
    "#                 y=pos_keep[:, 1],\n",
    "#                 z=pos_keep[:, 2],\n",
    "#                 mode='markers',\n",
    "#                 marker=dict(\n",
    "#                     size=3,\n",
    "#                     color=color_keep_hex,  # Use hex colors for kept Gaussians\n",
    "#                     opacity=0.7,\n",
    "#                 ),\n",
    "#                 name=\"Kept Gaussians\"\n",
    "#             ))\n",
    "\n",
    "#             title = f\"Pruning {prune_percentage:.2f}% of Gaussians\"\n",
    "#             fig.update_layout(\n",
    "#                 title=title,\n",
    "#                 scene=dict(\n",
    "#                     xaxis_title=\"X\",\n",
    "#                     yaxis_title=\"Y\",\n",
    "#                     zaxis_title=\"Z\",\n",
    "#                 ),\n",
    "#                 legend=dict(x=1, y=0.9)\n",
    "#             )\n",
    "\n",
    "#             fig.show()\n",
    "\n",
    "#             # Actually prune\n",
    "#             # gaussians.mask_splats(non_prune_mask)\n",
    "#             # gaussian_importance = gaussian_importance[non_prune_mask]\n",
    "#             # color_importance = color_importance[non_prune_mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------ Pruning ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important hyperparameters\n",
    "print('prune_threshold:', comp_params.prune_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Given a vector x ∈ R^D, we define its sensitivity as the maximum over its component’s sensitivity\n",
    "    color_importance_n = color_importance.amax(-1)\n",
    "    gaussian_importance_n = gaussian_sensitivity.amax(-1)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # ------------------ Prune ------------------\n",
    "    prune_threshold = comp_params.prune_threshold\n",
    "\n",
    "    if prune_threshold >= 0:\n",
    "        non_prune_mask = color_importance_n > prune_threshold\n",
    "\n",
    "        # # Get positions for each Gaussian\n",
    "        # positions = gaussians.get_xyz\n",
    "        \n",
    "        # # Separate the positions and sensitivities based on pruning mask\n",
    "        # pos_keep = positions[non_prune_mask].cpu().numpy()\n",
    "        # pos_prune = positions[~non_prune_mask].cpu().numpy()\n",
    "\n",
    "        # fig = go.Figure()\n",
    "\n",
    "        # # Scatter plot for Gaussians that will be kept\n",
    "        # fig.add_trace(go.Scatter3d(\n",
    "        #     x=pos_prune[:, 0],\n",
    "        #     y=pos_prune[:, 1],\n",
    "        #     z=pos_prune[:, 2],\n",
    "        #     mode='markers',\n",
    "        #     marker=dict(\n",
    "        #         size=3,\n",
    "        #         color='red',    \n",
    "        #         opacity=0.5,\n",
    "        #     ),\n",
    "        #     name=\"Pruned Gaussians\"\n",
    "        # ))\n",
    "\n",
    "        # # Scatter plot for Gaussians that will be pruned\n",
    "        # fig.add_trace(go.Scatter3d(\n",
    "        #     x=pos_keep[:, 0],\n",
    "        #     y=pos_keep[:, 1],\n",
    "        #     z=pos_keep[:, 2],\n",
    "        #     mode='markers',\n",
    "        #     marker=dict(\n",
    "        #         size=3,\n",
    "        #         color='blue',\n",
    "        #         opacity=0.7,\n",
    "        #     ),\n",
    "        #     name=\"Kept Gaussians\"\n",
    "        # ))\n",
    "\n",
    "        # prune_percentage = (1 - non_prune_mask.float().mean()) * 100\n",
    "\n",
    "        # title = f\"Pruning {prune_percentage:.2f}% of Gaussians\"\n",
    "        # fig.update_layout(\n",
    "        #     title=title,\n",
    "        #     scene=dict(\n",
    "        #         xaxis_title=\"X\",\n",
    "        #         yaxis_title=\"Y\",\n",
    "        #         zaxis_title=\"Z\",\n",
    "        #     ),\n",
    "        #     legend=dict(x=1, y=0.9)\n",
    "        # )\n",
    "\n",
    "        # fig.show()\n",
    "\n",
    "        gaussians.mask_splats(non_prune_mask)\n",
    "        gaussian_importance_n = gaussian_importance_n[non_prune_mask]\n",
    "        color_importance_n = color_importance_n[non_prune_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------ Color Compression ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important hyperparameters\n",
    "comp_params.color_codebook_size             # K = number of centroids = codebook size\n",
    "comp_params.color_importance_prune\n",
    "comp_params.color_importance_include\n",
    "comp_params.color_cluster_iterations = 1 # TODO: remove\n",
    "comp_params.color_decay\n",
    "comp_params.color_batch_size\n",
    "\n",
    "# Initialize the color codebook using parameters\n",
    "color_compression_settings = CompressionSettings(\n",
    "    codebook_size=comp_params.color_codebook_size,\n",
    "    importance_prune=comp_params.color_importance_prune,\n",
    "    importance_include=comp_params.color_importance_include,\n",
    "    steps=int(comp_params.color_cluster_iterations),\n",
    "    decay=comp_params.color_decay,\n",
    "    batch_size=comp_params.color_batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# def visualise_feature_space(features: torch.Tensor, use_tsne=False, title=\"2D Projection of Color Features\"):\n",
    "#     features_np = features.cpu().numpy()\n",
    "\n",
    "#     if use_tsne: # Careful: takes roughly 15 minutes to run (on my GPU)\n",
    "#         tsne = TSNE(n_components=2, random_state=0, perplexity=30, n_iter=300)\n",
    "#         features_2d = tsne.fit_transform(features_np)\n",
    "#     else:\n",
    "#         pca = PCA(n_components=2)\n",
    "#         features_2d = pca.fit_transform(features_np)\n",
    "\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     plt.scatter(features_2d[:, 0], features_2d[:, 1], s=1, alpha=0.5)\n",
    "#     plt.title(title)\n",
    "#     plt.xlabel(\"Component 1\")\n",
    "#     plt.ylabel(\"Component 2\")\n",
    "#     plt.show()\n",
    "\n",
    "# def visualise_feature_space(features: torch.Tensor, assignments: torch.Tensor, use_tsne=False, title=\"2D Projection of Color Features\"):\n",
    "#     features_np = features.cpu().numpy()\n",
    "#     assignments_np = assignments.cpu().numpy()  # Convert assignments to numpy\n",
    "\n",
    "#     # Perform dimensionality reduction\n",
    "#     if use_tsne:  # t-SNE is computationally expensive\n",
    "#         tsne = TSNE(n_components=2, random_state=0, perplexity=30, n_iter=300)\n",
    "#         features_2d = tsne.fit_transform(features_np)\n",
    "#     else:\n",
    "#         pca = PCA(n_components=2)\n",
    "#         features_2d = pca.fit_transform(features_np)\n",
    "\n",
    "#     # Get unique centroids and assign a color to each\n",
    "#     unique_assignments = np.unique(assignments_np)\n",
    "#     colors = plt.cm.get_cmap('tab10', len(unique_assignments))\n",
    "\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "\n",
    "#     # Plot each feature colored by its assigned centroid\n",
    "#     for i, centroid_idx in enumerate(unique_assignments):\n",
    "#         centroid_features = features_2d[assignments_np == centroid_idx]\n",
    "#         plt.scatter(centroid_features[:, 0], centroid_features[:, 1], s=1, color=colors(i), alpha=0.3, label=f\"Centroid {centroid_idx}\")\n",
    "\n",
    "#     plt.title(title)\n",
    "#     plt.xlabel(\"Component 1\")\n",
    "#     plt.ylabel(\"Component 2\")\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "def visualise_feature_space_centroids(features: torch.Tensor, centroids: torch.Tensor, use_tsne=False, title=\"2D Projection of Color Features\"):\n",
    "    features_np = features.cpu().numpy()\n",
    "    centroids_np = centroids.cpu().numpy()\n",
    "\n",
    "    if use_tsne: # Careful: takes roughly 15 minutes to run (on my GPU)\n",
    "        tsne = TSNE(n_components=2, random_state=0, perplexity=30, n_iter=300)\n",
    "        features_2d = tsne.fit_transform(features_np)\n",
    "        centroids_2d = tsne.fit_transform(centroids_np)\n",
    "    else:\n",
    "        pca = PCA(n_components=2)\n",
    "        features_2d = pca.fit_transform(features_np)\n",
    "        centroids_2d = pca.fit_transform(centroids_np)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    plt.scatter(features_2d[:, 0], features_2d[:, 1], s=1, alpha=0.5)\n",
    "    plt.scatter(centroids_2d[:, 0], centroids_2d[:, 1], color='red', s=1, label=\"Centroids\")\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Component 1\")\n",
    "    plt.ylabel(\"Component 2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compression.vq import VectorQuantize\n",
    "from tqdm import trange\n",
    "import gc\n",
    "\n",
    "def vq_features_vis(\n",
    "    features: torch.Tensor,\n",
    "    importance: torch.Tensor,\n",
    "    codebook_size: int,\n",
    "    vq_chunk: int = 2**16,\n",
    "    steps: int = 1000,\n",
    "    decay: float = 0.8,\n",
    "    scale_normalize: bool = False,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    importance_n = importance/importance.max()\n",
    "    vq_model = VectorQuantize(\n",
    "        channels=features.shape[-1],\n",
    "        codebook_size=codebook_size,\n",
    "        decay=decay,\n",
    "    ).to(device=features.device)\n",
    "\n",
    "    vq_model.uniform_init(features)\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    for i in trange(steps):\n",
    "        batch = torch.randint(low=0, high=features.shape[0], size=[vq_chunk])\n",
    "        vq_feature = features[batch]\n",
    "        error = vq_model.update(vq_feature, importance=importance_n[batch]).mean().item()\n",
    "        errors.append(error)\n",
    "\n",
    "        _, idx = vq_model(features)\n",
    "        # visualise_feature_space(features, idx, use_tsne=False, title=f\"2D Projection of Color Features - Iteration {i+1}\")\n",
    "        visualise_feature_space_centroids(features, vq_model.codebook.data, use_tsne=False, title=f\"2D Projection of Color Features - Iteration {i+1}\")\n",
    "\n",
    "        if scale_normalize:\n",
    "            # this computes the trace of the codebook covariance matrices\n",
    "            # we devide by the trace to ensure that matrices have normalized eigenvalues / scales\n",
    "            tr = vq_model.codebook[:, [0, 3, 5]].sum(-1)\n",
    "            vq_model.codebook /= tr[:, None]\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    start = time.time()\n",
    "    _, vq_indices = vq_model(features)\n",
    "    torch.cuda.synchronize(device=vq_indices.device)\n",
    "    end = time.time()\n",
    "    print(f\"calculating indices took {end-start} seconds \")\n",
    "    return vq_model.codebook.data.detach(), vq_indices.detach(), errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compression.vq import join_features\n",
    "\n",
    "def compress_color_vis(\n",
    "    gaussians: GaussianModel,\n",
    "    color_importance_n: torch.Tensor,\n",
    "    color_comp: CompressionSettings,\n",
    "    color_compress_non_dir: bool,\n",
    "):\n",
    "    keep_mask = color_importance_n > color_comp.importance_include\n",
    "\n",
    "    print(f\"color keep: {keep_mask.float().mean()*100:.2f}%\")\n",
    "\n",
    "    vq_mask_c = ~keep_mask\n",
    "\n",
    "    # remove zero sh component\n",
    "    if color_compress_non_dir:\n",
    "        n_sh_coefs = gaussians.get_features.shape[1]\n",
    "        color_features = gaussians.get_features.detach().flatten(-2)\n",
    "    else:\n",
    "        n_sh_coefs = gaussians.get_features.shape[1] - 1\n",
    "        color_features = gaussians.get_features[:, 1:].detach().flatten(-2)\n",
    "\n",
    "    if vq_mask_c.any():\n",
    "        color_codebook, color_vq_indices, errors = vq_features_vis(\n",
    "            color_features[vq_mask_c],\n",
    "            color_importance_n[vq_mask_c],\n",
    "            color_comp.codebook_size,\n",
    "            color_comp.batch_size,\n",
    "            color_comp.steps,\n",
    "        )\n",
    "    else:\n",
    "        color_codebook = torch.empty(\n",
    "            (0, color_features.shape[-1]), device=color_features.device\n",
    "        )\n",
    "        color_vq_indices = torch.empty(\n",
    "            (0,), device=color_features.device, dtype=torch.long\n",
    "        )\n",
    "\n",
    "    all_features = color_features\n",
    "    compressed_features, indices = join_features(\n",
    "        all_features, keep_mask, color_codebook, color_vq_indices\n",
    "    )\n",
    "\n",
    "    gaussians.set_color_indexed(compressed_features.reshape(-1, n_sh_coefs, 3), indices)\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    color_comp = color_compression_settings if not comp_params.not_compress_color else None\n",
    "    if color_comp is not None:\n",
    "        color_errors = compress_color_vis(\n",
    "            gaussians,\n",
    "            color_importance_n,\n",
    "            color_comp,\n",
    "            comp_params.color_compress_non_dir,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_curve(errors=[]):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(errors, label='Quantization Error')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Quantization Error')\n",
    "    plt.title('Quantization Error Over Iterations')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error_curve(color_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------ Gaussian Shape Compression ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important hyperparameters:\n",
    "comp_params.gaussian_codebook_size\n",
    "comp_params.gaussian_importance_include\n",
    "comp_params.gaussian_cluster_iterations = 10 # TODO: remove\n",
    "comp_params.gaussian_decay\n",
    "comp_params.gaussian_batch_size\n",
    "\n",
    "# Initialize the Gaussian shape codebook using parameters\n",
    "gaussian_compression_settings = CompressionSettings(\n",
    "    codebook_size=comp_params.gaussian_codebook_size,\n",
    "    importance_prune=None,\n",
    "    importance_include=comp_params.gaussian_importance_include,\n",
    "    steps=int(comp_params.gaussian_cluster_iterations),\n",
    "    decay=comp_params.gaussian_decay,\n",
    "    batch_size=comp_params.gaussian_batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.splats import to_full_cov, extract_rot_scale\n",
    "\n",
    "def compress_covariance_vis(\n",
    "    gaussians: GaussianModel,\n",
    "    gaussian_importance_n: torch.Tensor,\n",
    "    gaussian_comp: CompressionSettings,\n",
    "):\n",
    "\n",
    "    keep_mask_g = gaussian_importance_n > gaussian_comp.importance_include\n",
    "\n",
    "    vq_mask_g = ~keep_mask_g\n",
    "\n",
    "    print(f\"gaussians keep: {keep_mask_g.float().mean()*100:.2f}%\")\n",
    "\n",
    "    covariance = gaussians.get_normalized_covariance(strip_sym=True).detach()\n",
    "\n",
    "    if vq_mask_g.any():\n",
    "        cov_codebook, cov_vq_indices, errors = vq_features_vis(\n",
    "            covariance[vq_mask_g],\n",
    "            gaussian_importance_n[vq_mask_g],\n",
    "            gaussian_comp.codebook_size,\n",
    "            gaussian_comp.batch_size,\n",
    "            gaussian_comp.steps,\n",
    "            scale_normalize=True,\n",
    "        )\n",
    "    else:\n",
    "        cov_codebook = torch.empty(\n",
    "            (0, covariance.shape[1], 1), device=covariance.device\n",
    "        )\n",
    "        cov_vq_indices = torch.empty((0,), device=covariance.device, dtype=torch.long)\n",
    "\n",
    "    compressed_cov, cov_indices = join_features(\n",
    "        covariance,\n",
    "        keep_mask_g,\n",
    "        cov_codebook,\n",
    "        cov_vq_indices,\n",
    "    )\n",
    "\n",
    "    rot_vq, scale_vq = extract_rot_scale(to_full_cov(compressed_cov))\n",
    "\n",
    "    gaussians.set_gaussian_indexed(\n",
    "        rot_vq.to(compressed_cov.device),\n",
    "        scale_vq.to(compressed_cov.device),\n",
    "        cov_indices,\n",
    "    )\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    gaussian_comp = gaussian_compression_settings if not comp_params.not_compress_gaussians else None\n",
    "    if gaussian_comp is not None:\n",
    "        shape_errors = compress_covariance_vis(\n",
    "            gaussians,\n",
    "            gaussian_importance_n,\n",
    "            gaussian_comp,\n",
    "        )\n",
    "\n",
    "end_time = time.time()\n",
    "timings[\"clustering\"]=end_time-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error_curve(shape_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c3dgs_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
